{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20161647_project_3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKTPDUGVKpKJfvuZQDaN59"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xa76bjHrBXD5","executionInfo":{"status":"ok","timestamp":1653478955825,"user_tz":-540,"elapsed":6239,"user":{"displayName":"조이준","userId":"18430695341039920489"}}},"outputs":[],"source":["import os, random\n","import keras\n","from keras.datasets import fashion_mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, BatchNormalization, Dropout\n","from keras.utils import np_utils\n","import numpy as np\n","import tensorflow as tf\n","os.path.expanduser = lambda path: './'"]},{"cell_type":"code","source":["batch_size = 128\n","num_classes = 10\n","epochs = 60\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","\n","x_train = x_train.reshape(60000, 784)\n","x_test = x_test.reshape(10000, 784)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","# regularization\n","x_train /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdegSqmABoBO","executionInfo":{"status":"ok","timestamp":1653478961557,"user_tz":-540,"elapsed":1374,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"5988a037-f9cb-4ad9-cea4-fe6e3cdbd309"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n","60000 train samples\n","10000 test samples\n"]}]},{"cell_type":"markdown","source":["# Define Model Function by Dropout rate without BN"],"metadata":{"id":"PR67yNBjBsNW"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"RJBY4LURBsG1"}},{"cell_type":"code","source":["# for reproducibility\n","import random, os\n","os.environ['PYTHONHASHSEED']='0'\n","random.seed(123)\n","np.random.seed(123)\n","tf.random.set_seed(123)\n","sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n","                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n","from tensorflow.python.keras import backend as K\n","K.set_session(sess)\n","\n","\n","\n","kernel_initializer='glorot_uniform'\n","activation_function = 'relu'\n","\n","def Model_K(k):\n","    with tf.device('/cpu:0'):\n","        model = Sequential()\n","        model.add(Dense(512,activation='relu', input_shape=(784,)))\n","        model.add(Dropout(k))\n","        model.add(Dense(512,activation='relu'))\n","        model.add(Dropout(k))\n","        model.add(Dense(num_classes, activation='softmax'))\n","        \n","        model.summary()\n","        \n","        model.compile(loss='categorical_crossentropy',\n","                     optimizer='sgd',\n","                     metrics=['accuracy'])\n","    return model"],"metadata":{"id":"s49rMJpvBqk9","executionInfo":{"status":"ok","timestamp":1653478977534,"user_tz":-540,"elapsed":603,"user":{"displayName":"조이준","userId":"18430695341039920489"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["model02 = Model_K(0.2)\n","model05 = Model_K(0.5)\n","model08 = Model_K(0.8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vc8_KI_FButU","executionInfo":{"status":"ok","timestamp":1653478983090,"user_tz":-540,"elapsed":1199,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"227c79b5-51c5-405a-979b-9ca4442d7b04"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 512)               401920    \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 669,706\n","Trainable params: 669,706\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 512)               401920    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dropout_3 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 669,706\n","Trainable params: 669,706\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 512)               401920    \n","                                                                 \n"," dropout_4 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dropout_5 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 669,706\n","Trainable params: 669,706\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["history02 = model02.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyq3uzl2Bv5s","executionInfo":{"status":"ok","timestamp":1653479433933,"user_tz":-540,"elapsed":433800,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"f3f6abc3-5fdc-4b81-e288-0e23e9b717a4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","375/375 [==============================] - 11s 26ms/step - loss: 1.1965 - accuracy: 0.6196 - val_loss: 0.7337 - val_accuracy: 0.7555\n","Epoch 2/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7406 - accuracy: 0.7519 - val_loss: 0.6155 - val_accuracy: 0.7908\n","Epoch 3/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6476 - accuracy: 0.7794 - val_loss: 0.5577 - val_accuracy: 0.8115\n","Epoch 4/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.5926 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.8217\n","Epoch 5/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.5588 - accuracy: 0.8096 - val_loss: 0.5022 - val_accuracy: 0.8296\n","Epoch 6/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5347 - accuracy: 0.8160 - val_loss: 0.4841 - val_accuracy: 0.8357\n","Epoch 7/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5134 - accuracy: 0.8235 - val_loss: 0.4705 - val_accuracy: 0.8390\n","Epoch 8/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4967 - accuracy: 0.8299 - val_loss: 0.4583 - val_accuracy: 0.8438\n","Epoch 9/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4863 - accuracy: 0.8313 - val_loss: 0.4557 - val_accuracy: 0.8411\n","Epoch 10/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4727 - accuracy: 0.8355 - val_loss: 0.4434 - val_accuracy: 0.8470\n","Epoch 11/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.4651 - accuracy: 0.8389 - val_loss: 0.4386 - val_accuracy: 0.8477\n","Epoch 12/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.4571 - accuracy: 0.8418 - val_loss: 0.4285 - val_accuracy: 0.8505\n","Epoch 13/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.4450 - accuracy: 0.8447 - val_loss: 0.4261 - val_accuracy: 0.8508\n","Epoch 14/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.4399 - accuracy: 0.8472 - val_loss: 0.4172 - val_accuracy: 0.8555\n","Epoch 15/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4329 - accuracy: 0.8498 - val_loss: 0.4088 - val_accuracy: 0.8581\n","Epoch 16/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4258 - accuracy: 0.8497 - val_loss: 0.4092 - val_accuracy: 0.8583\n","Epoch 17/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4203 - accuracy: 0.8533 - val_loss: 0.4021 - val_accuracy: 0.8596\n","Epoch 18/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.4152 - accuracy: 0.8533 - val_loss: 0.3995 - val_accuracy: 0.8621\n","Epoch 19/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4109 - accuracy: 0.8562 - val_loss: 0.3920 - val_accuracy: 0.8627\n","Epoch 20/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.4043 - accuracy: 0.8576 - val_loss: 0.3896 - val_accuracy: 0.8638\n","Epoch 21/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3971 - accuracy: 0.8615 - val_loss: 0.3865 - val_accuracy: 0.8640\n","Epoch 22/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3957 - accuracy: 0.8606 - val_loss: 0.3874 - val_accuracy: 0.8633\n","Epoch 23/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3908 - accuracy: 0.8613 - val_loss: 0.3814 - val_accuracy: 0.8652\n","Epoch 24/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.3880 - accuracy: 0.8628 - val_loss: 0.3765 - val_accuracy: 0.8692\n","Epoch 25/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3829 - accuracy: 0.8657 - val_loss: 0.3739 - val_accuracy: 0.8689\n","Epoch 26/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3781 - accuracy: 0.8661 - val_loss: 0.3707 - val_accuracy: 0.8698\n","Epoch 27/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3759 - accuracy: 0.8674 - val_loss: 0.3696 - val_accuracy: 0.8695\n","Epoch 28/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3716 - accuracy: 0.8671 - val_loss: 0.3675 - val_accuracy: 0.8703\n","Epoch 29/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3688 - accuracy: 0.8684 - val_loss: 0.3641 - val_accuracy: 0.8723\n","Epoch 30/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3658 - accuracy: 0.8702 - val_loss: 0.3625 - val_accuracy: 0.8721\n","Epoch 31/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3618 - accuracy: 0.8715 - val_loss: 0.3605 - val_accuracy: 0.8722\n","Epoch 32/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3592 - accuracy: 0.8721 - val_loss: 0.3593 - val_accuracy: 0.8733\n","Epoch 33/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3562 - accuracy: 0.8730 - val_loss: 0.3570 - val_accuracy: 0.8736\n","Epoch 34/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3544 - accuracy: 0.8740 - val_loss: 0.3563 - val_accuracy: 0.8732\n","Epoch 35/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3498 - accuracy: 0.8755 - val_loss: 0.3546 - val_accuracy: 0.8736\n","Epoch 36/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3495 - accuracy: 0.8750 - val_loss: 0.3500 - val_accuracy: 0.8772\n","Epoch 37/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3454 - accuracy: 0.8763 - val_loss: 0.3498 - val_accuracy: 0.8763\n","Epoch 38/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3445 - accuracy: 0.8757 - val_loss: 0.3472 - val_accuracy: 0.8759\n","Epoch 39/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3421 - accuracy: 0.8779 - val_loss: 0.3476 - val_accuracy: 0.8768\n","Epoch 40/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3412 - accuracy: 0.8773 - val_loss: 0.3451 - val_accuracy: 0.8772\n","Epoch 41/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3376 - accuracy: 0.8794 - val_loss: 0.3479 - val_accuracy: 0.8773\n","Epoch 42/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3339 - accuracy: 0.8809 - val_loss: 0.3428 - val_accuracy: 0.8783\n","Epoch 43/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.3322 - accuracy: 0.8812 - val_loss: 0.3416 - val_accuracy: 0.8787\n","Epoch 44/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3305 - accuracy: 0.8815 - val_loss: 0.3398 - val_accuracy: 0.8790\n","Epoch 45/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3274 - accuracy: 0.8829 - val_loss: 0.3424 - val_accuracy: 0.8788\n","Epoch 46/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3273 - accuracy: 0.8823 - val_loss: 0.3363 - val_accuracy: 0.8808\n","Epoch 47/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3240 - accuracy: 0.8835 - val_loss: 0.3370 - val_accuracy: 0.8807\n","Epoch 48/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3220 - accuracy: 0.8854 - val_loss: 0.3365 - val_accuracy: 0.8794\n","Epoch 49/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3197 - accuracy: 0.8857 - val_loss: 0.3335 - val_accuracy: 0.8806\n","Epoch 50/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3179 - accuracy: 0.8856 - val_loss: 0.3364 - val_accuracy: 0.8811\n","Epoch 51/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3163 - accuracy: 0.8878 - val_loss: 0.3304 - val_accuracy: 0.8830\n","Epoch 52/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3123 - accuracy: 0.8880 - val_loss: 0.3295 - val_accuracy: 0.8825\n","Epoch 53/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3125 - accuracy: 0.8882 - val_loss: 0.3329 - val_accuracy: 0.8826\n","Epoch 54/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.3123 - accuracy: 0.8870 - val_loss: 0.3274 - val_accuracy: 0.8832\n","Epoch 55/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3076 - accuracy: 0.8885 - val_loss: 0.3283 - val_accuracy: 0.8825\n","Epoch 56/60\n","375/375 [==============================] - 9s 24ms/step - loss: 0.3069 - accuracy: 0.8904 - val_loss: 0.3267 - val_accuracy: 0.8838\n","Epoch 57/60\n","375/375 [==============================] - 9s 24ms/step - loss: 0.3065 - accuracy: 0.8911 - val_loss: 0.3242 - val_accuracy: 0.8848\n","Epoch 58/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.3031 - accuracy: 0.8912 - val_loss: 0.3236 - val_accuracy: 0.8850\n","Epoch 59/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.3019 - accuracy: 0.8921 - val_loss: 0.3236 - val_accuracy: 0.8855\n","Epoch 60/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.3001 - accuracy: 0.8929 - val_loss: 0.3223 - val_accuracy: 0.8853\n"]}]},{"cell_type":"code","source":["history05 = model05.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7NEt9ZqByUQ","executionInfo":{"status":"ok","timestamp":1653479876212,"user_tz":-540,"elapsed":442289,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"c89068aa-190e-4b52-8870-2261a419e770"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","375/375 [==============================] - 8s 19ms/step - loss: 1.4242 - accuracy: 0.5080 - val_loss: 0.8076 - val_accuracy: 0.7227\n","Epoch 2/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.8997 - accuracy: 0.6824 - val_loss: 0.6740 - val_accuracy: 0.7628\n","Epoch 3/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7752 - accuracy: 0.7293 - val_loss: 0.6132 - val_accuracy: 0.7811\n","Epoch 4/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7042 - accuracy: 0.7532 - val_loss: 0.5727 - val_accuracy: 0.7989\n","Epoch 5/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6601 - accuracy: 0.7721 - val_loss: 0.5393 - val_accuracy: 0.8113\n","Epoch 6/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6249 - accuracy: 0.7847 - val_loss: 0.5182 - val_accuracy: 0.8198\n","Epoch 7/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5964 - accuracy: 0.7904 - val_loss: 0.5003 - val_accuracy: 0.8247\n","Epoch 8/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5758 - accuracy: 0.7998 - val_loss: 0.4853 - val_accuracy: 0.8301\n","Epoch 9/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5584 - accuracy: 0.8060 - val_loss: 0.4757 - val_accuracy: 0.8303\n","Epoch 10/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.5437 - accuracy: 0.8106 - val_loss: 0.4643 - val_accuracy: 0.8352\n","Epoch 11/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5300 - accuracy: 0.8142 - val_loss: 0.4565 - val_accuracy: 0.8381\n","Epoch 12/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5163 - accuracy: 0.8193 - val_loss: 0.4478 - val_accuracy: 0.8401\n","Epoch 13/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5105 - accuracy: 0.8215 - val_loss: 0.4413 - val_accuracy: 0.8421\n","Epoch 14/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.4990 - accuracy: 0.8251 - val_loss: 0.4336 - val_accuracy: 0.8446\n","Epoch 15/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4900 - accuracy: 0.8278 - val_loss: 0.4259 - val_accuracy: 0.8472\n","Epoch 16/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.4814 - accuracy: 0.8304 - val_loss: 0.4232 - val_accuracy: 0.8497\n","Epoch 17/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4737 - accuracy: 0.8345 - val_loss: 0.4174 - val_accuracy: 0.8498\n","Epoch 18/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4675 - accuracy: 0.8363 - val_loss: 0.4137 - val_accuracy: 0.8520\n","Epoch 19/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.4652 - accuracy: 0.8364 - val_loss: 0.4076 - val_accuracy: 0.8546\n","Epoch 20/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4619 - accuracy: 0.8358 - val_loss: 0.4032 - val_accuracy: 0.8550\n","Epoch 21/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4527 - accuracy: 0.8404 - val_loss: 0.4023 - val_accuracy: 0.8553\n","Epoch 22/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4486 - accuracy: 0.8410 - val_loss: 0.3988 - val_accuracy: 0.8562\n","Epoch 23/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4429 - accuracy: 0.8438 - val_loss: 0.3961 - val_accuracy: 0.8577\n","Epoch 24/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4392 - accuracy: 0.8440 - val_loss: 0.3905 - val_accuracy: 0.8586\n","Epoch 25/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.4359 - accuracy: 0.8461 - val_loss: 0.3875 - val_accuracy: 0.8601\n","Epoch 26/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4302 - accuracy: 0.8481 - val_loss: 0.3852 - val_accuracy: 0.8623\n","Epoch 27/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4239 - accuracy: 0.8486 - val_loss: 0.3825 - val_accuracy: 0.8623\n","Epoch 28/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4239 - accuracy: 0.8507 - val_loss: 0.3813 - val_accuracy: 0.8629\n","Epoch 29/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.4198 - accuracy: 0.8509 - val_loss: 0.3771 - val_accuracy: 0.8643\n","Epoch 30/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4162 - accuracy: 0.8524 - val_loss: 0.3779 - val_accuracy: 0.8626\n","Epoch 31/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4120 - accuracy: 0.8544 - val_loss: 0.3728 - val_accuracy: 0.8651\n","Epoch 32/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4103 - accuracy: 0.8544 - val_loss: 0.3736 - val_accuracy: 0.8654\n","Epoch 33/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4076 - accuracy: 0.8536 - val_loss: 0.3704 - val_accuracy: 0.8669\n","Epoch 34/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4043 - accuracy: 0.8570 - val_loss: 0.3687 - val_accuracy: 0.8672\n","Epoch 35/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4018 - accuracy: 0.8584 - val_loss: 0.3673 - val_accuracy: 0.8683\n","Epoch 36/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4003 - accuracy: 0.8587 - val_loss: 0.3628 - val_accuracy: 0.8695\n","Epoch 37/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3965 - accuracy: 0.8584 - val_loss: 0.3626 - val_accuracy: 0.8692\n","Epoch 38/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3923 - accuracy: 0.8601 - val_loss: 0.3597 - val_accuracy: 0.8707\n","Epoch 39/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3915 - accuracy: 0.8606 - val_loss: 0.3592 - val_accuracy: 0.8710\n","Epoch 40/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3897 - accuracy: 0.8626 - val_loss: 0.3577 - val_accuracy: 0.8716\n","Epoch 41/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3851 - accuracy: 0.8645 - val_loss: 0.3582 - val_accuracy: 0.8713\n","Epoch 42/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3826 - accuracy: 0.8653 - val_loss: 0.3544 - val_accuracy: 0.8713\n","Epoch 43/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3826 - accuracy: 0.8650 - val_loss: 0.3528 - val_accuracy: 0.8727\n","Epoch 44/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3828 - accuracy: 0.8640 - val_loss: 0.3508 - val_accuracy: 0.8733\n","Epoch 45/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3777 - accuracy: 0.8656 - val_loss: 0.3497 - val_accuracy: 0.8750\n","Epoch 46/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3747 - accuracy: 0.8668 - val_loss: 0.3481 - val_accuracy: 0.8751\n","Epoch 47/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3739 - accuracy: 0.8658 - val_loss: 0.3485 - val_accuracy: 0.8754\n","Epoch 48/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.3708 - accuracy: 0.8666 - val_loss: 0.3462 - val_accuracy: 0.8752\n","Epoch 49/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3726 - accuracy: 0.8675 - val_loss: 0.3450 - val_accuracy: 0.8755\n","Epoch 50/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3691 - accuracy: 0.8694 - val_loss: 0.3468 - val_accuracy: 0.8756\n","Epoch 51/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3658 - accuracy: 0.8691 - val_loss: 0.3422 - val_accuracy: 0.8773\n","Epoch 52/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3665 - accuracy: 0.8706 - val_loss: 0.3418 - val_accuracy: 0.8764\n","Epoch 53/60\n","375/375 [==============================] - 7s 18ms/step - loss: 0.3603 - accuracy: 0.8709 - val_loss: 0.3403 - val_accuracy: 0.8763\n","Epoch 54/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3582 - accuracy: 0.8718 - val_loss: 0.3402 - val_accuracy: 0.8760\n","Epoch 55/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3586 - accuracy: 0.8719 - val_loss: 0.3395 - val_accuracy: 0.8766\n","Epoch 56/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3573 - accuracy: 0.8730 - val_loss: 0.3376 - val_accuracy: 0.8774\n","Epoch 57/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3548 - accuracy: 0.8748 - val_loss: 0.3361 - val_accuracy: 0.8783\n","Epoch 58/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3546 - accuracy: 0.8726 - val_loss: 0.3350 - val_accuracy: 0.8786\n","Epoch 59/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3549 - accuracy: 0.8732 - val_loss: 0.3349 - val_accuracy: 0.8788\n","Epoch 60/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.3507 - accuracy: 0.8746 - val_loss: 0.3335 - val_accuracy: 0.8801\n"]}]},{"cell_type":"code","source":["history08 = model08.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKb9RmWPBzdv","executionInfo":{"status":"ok","timestamp":1653480318652,"user_tz":-540,"elapsed":442457,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"30cc78a3-55aa-4657-db5a-29127329afcb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","375/375 [==============================] - 8s 19ms/step - loss: 1.9693 - accuracy: 0.3015 - val_loss: 1.2125 - val_accuracy: 0.6725\n","Epoch 2/60\n","375/375 [==============================] - 7s 19ms/step - loss: 1.3743 - accuracy: 0.4982 - val_loss: 0.8933 - val_accuracy: 0.7011\n","Epoch 3/60\n","375/375 [==============================] - 7s 19ms/step - loss: 1.1483 - accuracy: 0.5746 - val_loss: 0.7836 - val_accuracy: 0.7154\n","Epoch 4/60\n","375/375 [==============================] - 7s 19ms/step - loss: 1.0305 - accuracy: 0.6171 - val_loss: 0.7300 - val_accuracy: 0.7330\n","Epoch 5/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.9516 - accuracy: 0.6440 - val_loss: 0.6860 - val_accuracy: 0.7523\n","Epoch 6/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.9004 - accuracy: 0.6649 - val_loss: 0.6623 - val_accuracy: 0.7590\n","Epoch 7/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.8540 - accuracy: 0.6825 - val_loss: 0.6345 - val_accuracy: 0.7678\n","Epoch 8/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.8257 - accuracy: 0.6965 - val_loss: 0.6144 - val_accuracy: 0.7756\n","Epoch 9/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.8019 - accuracy: 0.7048 - val_loss: 0.5982 - val_accuracy: 0.7901\n","Epoch 10/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7724 - accuracy: 0.7168 - val_loss: 0.5841 - val_accuracy: 0.7947\n","Epoch 11/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7532 - accuracy: 0.7250 - val_loss: 0.5698 - val_accuracy: 0.8024\n","Epoch 12/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7279 - accuracy: 0.7336 - val_loss: 0.5546 - val_accuracy: 0.8059\n","Epoch 13/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7190 - accuracy: 0.7400 - val_loss: 0.5448 - val_accuracy: 0.8093\n","Epoch 14/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.7011 - accuracy: 0.7457 - val_loss: 0.5371 - val_accuracy: 0.8138\n","Epoch 15/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6878 - accuracy: 0.7540 - val_loss: 0.5270 - val_accuracy: 0.8197\n","Epoch 16/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6776 - accuracy: 0.7590 - val_loss: 0.5194 - val_accuracy: 0.8209\n","Epoch 17/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.6664 - accuracy: 0.7609 - val_loss: 0.5118 - val_accuracy: 0.8220\n","Epoch 18/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6525 - accuracy: 0.7654 - val_loss: 0.5040 - val_accuracy: 0.8247\n","Epoch 19/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.6450 - accuracy: 0.7698 - val_loss: 0.4958 - val_accuracy: 0.8260\n","Epoch 20/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6395 - accuracy: 0.7739 - val_loss: 0.4929 - val_accuracy: 0.8288\n","Epoch 21/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6272 - accuracy: 0.7792 - val_loss: 0.4867 - val_accuracy: 0.8268\n","Epoch 22/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.6213 - accuracy: 0.7797 - val_loss: 0.4834 - val_accuracy: 0.8322\n","Epoch 23/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.6151 - accuracy: 0.7838 - val_loss: 0.4766 - val_accuracy: 0.8323\n","Epoch 24/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.6039 - accuracy: 0.7879 - val_loss: 0.4723 - val_accuracy: 0.8335\n","Epoch 25/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5995 - accuracy: 0.7889 - val_loss: 0.4695 - val_accuracy: 0.8333\n","Epoch 26/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5910 - accuracy: 0.7927 - val_loss: 0.4625 - val_accuracy: 0.8356\n","Epoch 27/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5864 - accuracy: 0.7956 - val_loss: 0.4600 - val_accuracy: 0.8355\n","Epoch 28/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5827 - accuracy: 0.7957 - val_loss: 0.4624 - val_accuracy: 0.8361\n","Epoch 29/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5781 - accuracy: 0.7981 - val_loss: 0.4522 - val_accuracy: 0.8393\n","Epoch 30/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5801 - accuracy: 0.7986 - val_loss: 0.4522 - val_accuracy: 0.8393\n","Epoch 31/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5696 - accuracy: 0.8008 - val_loss: 0.4482 - val_accuracy: 0.8388\n","Epoch 32/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5637 - accuracy: 0.8044 - val_loss: 0.4450 - val_accuracy: 0.8409\n","Epoch 33/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5610 - accuracy: 0.8023 - val_loss: 0.4429 - val_accuracy: 0.8411\n","Epoch 34/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5565 - accuracy: 0.8046 - val_loss: 0.4402 - val_accuracy: 0.8422\n","Epoch 35/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5489 - accuracy: 0.8074 - val_loss: 0.4388 - val_accuracy: 0.8438\n","Epoch 36/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5544 - accuracy: 0.8072 - val_loss: 0.4356 - val_accuracy: 0.8441\n","Epoch 37/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5482 - accuracy: 0.8087 - val_loss: 0.4330 - val_accuracy: 0.8448\n","Epoch 38/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5462 - accuracy: 0.8098 - val_loss: 0.4319 - val_accuracy: 0.8448\n","Epoch 39/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5413 - accuracy: 0.8125 - val_loss: 0.4318 - val_accuracy: 0.8448\n","Epoch 40/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5433 - accuracy: 0.8112 - val_loss: 0.4287 - val_accuracy: 0.8461\n","Epoch 41/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5351 - accuracy: 0.8146 - val_loss: 0.4256 - val_accuracy: 0.8483\n","Epoch 42/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5290 - accuracy: 0.8146 - val_loss: 0.4241 - val_accuracy: 0.8476\n","Epoch 43/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5291 - accuracy: 0.8157 - val_loss: 0.4219 - val_accuracy: 0.8499\n","Epoch 44/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5245 - accuracy: 0.8184 - val_loss: 0.4195 - val_accuracy: 0.8506\n","Epoch 45/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5227 - accuracy: 0.8198 - val_loss: 0.4190 - val_accuracy: 0.8504\n","Epoch 46/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.5198 - accuracy: 0.8203 - val_loss: 0.4190 - val_accuracy: 0.8511\n","Epoch 47/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5184 - accuracy: 0.8202 - val_loss: 0.4155 - val_accuracy: 0.8515\n","Epoch 48/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5130 - accuracy: 0.8207 - val_loss: 0.4143 - val_accuracy: 0.8527\n","Epoch 49/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5134 - accuracy: 0.8226 - val_loss: 0.4124 - val_accuracy: 0.8535\n","Epoch 50/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5079 - accuracy: 0.8239 - val_loss: 0.4109 - val_accuracy: 0.8537\n","Epoch 51/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5089 - accuracy: 0.8228 - val_loss: 0.4107 - val_accuracy: 0.8528\n","Epoch 52/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.5084 - accuracy: 0.8240 - val_loss: 0.4100 - val_accuracy: 0.8541\n","Epoch 53/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5064 - accuracy: 0.8249 - val_loss: 0.4105 - val_accuracy: 0.8521\n","Epoch 54/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5027 - accuracy: 0.8249 - val_loss: 0.4075 - val_accuracy: 0.8541\n","Epoch 55/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.5013 - accuracy: 0.8260 - val_loss: 0.4068 - val_accuracy: 0.8544\n","Epoch 56/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.4941 - accuracy: 0.8295 - val_loss: 0.4058 - val_accuracy: 0.8552\n","Epoch 57/60\n","375/375 [==============================] - 7s 19ms/step - loss: 0.4924 - accuracy: 0.8287 - val_loss: 0.4025 - val_accuracy: 0.8558\n","Epoch 58/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.4958 - accuracy: 0.8270 - val_loss: 0.4028 - val_accuracy: 0.8563\n","Epoch 59/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.4940 - accuracy: 0.8287 - val_loss: 0.4013 - val_accuracy: 0.8576\n","Epoch 60/60\n","375/375 [==============================] - 7s 20ms/step - loss: 0.4881 - accuracy: 0.8316 - val_loss: 0.3995 - val_accuracy: 0.8587\n"]}]},{"cell_type":"markdown","source":["# Model Accuracy"],"metadata":{"id":"ZWulEdw0IKWV"}},{"cell_type":"code","source":["metrics02 = model02.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics02[1])\n","print(f'Accuracy: {metrics02[1]*100:.2f}%\\n')\n","\n","metrics05 = model05.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics05[1])\n","print(f'Accuracy: {metrics05[1]*100:.2f}%\\n')\n","\n","metrics08 = model08.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics08[1])\n","print(f'Accuracy: {metrics08[1]*100:.2f}%\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oy5RmooVB0fE","executionInfo":{"status":"ok","timestamp":1653480677106,"user_tz":-540,"elapsed":4872,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"e028f214-42ff-4274-d4cb-4cdf100a5387"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 6ms/step - loss: 0.3465 - accuracy: 0.8759\n","0.8758999705314636\n","Accuracy: 87.59%\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8708\n","0.8708000183105469\n","Accuracy: 87.08%\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8514\n","0.8514000177383423\n","Accuracy: 85.14%\n","\n"]}]},{"cell_type":"markdown","source":["# Model Function with Dropout and BN"],"metadata":{"id":"M_48X0p-IQ74"}},{"cell_type":"code","source":["def Model_KB(k):\n","    with tf.device('/cpu:0'):\n","        model = Sequential()\n","        model.add(Dense(512,activation='relu', input_shape=(784,)))\n","        model.add(Dropout(k))\n","        model.add(BatchNormalization())\n","        model.add(Dense(512,activation='relu'))\n","        model.add(Dropout(k))\n","        model.add(BatchNormalization())\n","        model.add(Dense(num_classes, activation='softmax'))\n","        \n","        model.summary()\n","        \n","        model.compile(loss='categorical_crossentropy',\n","                     optimizer='sgd',\n","                     metrics=['accuracy'])\n","    return model"],"metadata":{"id":"qdqmNqT8IMl6","executionInfo":{"status":"ok","timestamp":1653480734826,"user_tz":-540,"elapsed":12,"user":{"displayName":"조이준","userId":"18430695341039920489"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model02B = Model_KB(0.2)\n","model05B = Model_KB(0.5)\n","model08B = Model_KB(0.8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k_MKuUW9Ib3-","executionInfo":{"status":"ok","timestamp":1653480740053,"user_tz":-540,"elapsed":1348,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"9fee24b9-f857-4b0c-a2b4-a65df3716907"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_9 (Dense)             (None, 512)               401920    \n","                                                                 \n"," dropout_6 (Dropout)         (None, 512)               0         \n","                                                                 \n"," batch_normalization (BatchN  (None, 512)              2048      \n"," ormalization)                                                   \n","                                                                 \n"," dense_10 (Dense)            (None, 512)               262656    \n","                                                                 \n"," dropout_7 (Dropout)         (None, 512)               0         \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_11 (Dense)            (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 673,802\n","Trainable params: 671,754\n","Non-trainable params: 2,048\n","_________________________________________________________________\n","Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_12 (Dense)            (None, 512)               401920    \n","                                                                 \n"," dropout_8 (Dropout)         (None, 512)               0         \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_13 (Dense)            (None, 512)               262656    \n","                                                                 \n"," dropout_9 (Dropout)         (None, 512)               0         \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_14 (Dense)            (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 673,802\n","Trainable params: 671,754\n","Non-trainable params: 2,048\n","_________________________________________________________________\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_15 (Dense)            (None, 512)               401920    \n","                                                                 \n"," dropout_10 (Dropout)        (None, 512)               0         \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_16 (Dense)            (None, 512)               262656    \n","                                                                 \n"," dropout_11 (Dropout)        (None, 512)               0         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 512)              2048      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_17 (Dense)            (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 673,802\n","Trainable params: 671,754\n","Non-trainable params: 2,048\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["history02B = model02B.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GtQHVCf9Ic0v","executionInfo":{"status":"ok","timestamp":1653481260471,"user_tz":-540,"elapsed":503022,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"f1cc9554-97cf-49a7-abc0-5c4a86b1f2f5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","375/375 [==============================] - 9s 21ms/step - loss: 0.7263 - accuracy: 0.7488 - val_loss: 0.4976 - val_accuracy: 0.8298\n","Epoch 2/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.5092 - accuracy: 0.8183 - val_loss: 0.4091 - val_accuracy: 0.8506\n","Epoch 3/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.4584 - accuracy: 0.8373 - val_loss: 0.3871 - val_accuracy: 0.8606\n","Epoch 4/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.4284 - accuracy: 0.8454 - val_loss: 0.3759 - val_accuracy: 0.8643\n","Epoch 5/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.4037 - accuracy: 0.8543 - val_loss: 0.3590 - val_accuracy: 0.8712\n","Epoch 6/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.3857 - accuracy: 0.8602 - val_loss: 0.3539 - val_accuracy: 0.8723\n","Epoch 7/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.3718 - accuracy: 0.8663 - val_loss: 0.3460 - val_accuracy: 0.8761\n","Epoch 8/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.3594 - accuracy: 0.8709 - val_loss: 0.3407 - val_accuracy: 0.8781\n","Epoch 9/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.3464 - accuracy: 0.8748 - val_loss: 0.3370 - val_accuracy: 0.8800\n","Epoch 10/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.3394 - accuracy: 0.8780 - val_loss: 0.3295 - val_accuracy: 0.8827\n","Epoch 11/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.3312 - accuracy: 0.8796 - val_loss: 0.3314 - val_accuracy: 0.8812\n","Epoch 12/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.3221 - accuracy: 0.8823 - val_loss: 0.3214 - val_accuracy: 0.8842\n","Epoch 13/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.3133 - accuracy: 0.8858 - val_loss: 0.3263 - val_accuracy: 0.8808\n","Epoch 14/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.3064 - accuracy: 0.8880 - val_loss: 0.3180 - val_accuracy: 0.8852\n","Epoch 15/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.3006 - accuracy: 0.8910 - val_loss: 0.3176 - val_accuracy: 0.8882\n","Epoch 16/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2960 - accuracy: 0.8913 - val_loss: 0.3166 - val_accuracy: 0.8852\n","Epoch 17/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2902 - accuracy: 0.8934 - val_loss: 0.3151 - val_accuracy: 0.8878\n","Epoch 18/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2832 - accuracy: 0.8957 - val_loss: 0.3123 - val_accuracy: 0.8867\n","Epoch 19/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2802 - accuracy: 0.8971 - val_loss: 0.3104 - val_accuracy: 0.8866\n","Epoch 20/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2729 - accuracy: 0.8996 - val_loss: 0.3123 - val_accuracy: 0.8883\n","Epoch 21/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2675 - accuracy: 0.9016 - val_loss: 0.3085 - val_accuracy: 0.8890\n","Epoch 22/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2650 - accuracy: 0.9039 - val_loss: 0.3190 - val_accuracy: 0.8837\n","Epoch 23/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2618 - accuracy: 0.9038 - val_loss: 0.3146 - val_accuracy: 0.8862\n","Epoch 24/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2528 - accuracy: 0.9068 - val_loss: 0.3014 - val_accuracy: 0.8915\n","Epoch 25/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2519 - accuracy: 0.9074 - val_loss: 0.3084 - val_accuracy: 0.8882\n","Epoch 26/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2461 - accuracy: 0.9104 - val_loss: 0.3029 - val_accuracy: 0.8908\n","Epoch 27/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2423 - accuracy: 0.9106 - val_loss: 0.3039 - val_accuracy: 0.8916\n","Epoch 28/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2403 - accuracy: 0.9116 - val_loss: 0.3091 - val_accuracy: 0.8890\n","Epoch 29/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2382 - accuracy: 0.9112 - val_loss: 0.3096 - val_accuracy: 0.8901\n","Epoch 30/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2312 - accuracy: 0.9158 - val_loss: 0.3039 - val_accuracy: 0.8898\n","Epoch 31/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2297 - accuracy: 0.9142 - val_loss: 0.3035 - val_accuracy: 0.8911\n","Epoch 32/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2260 - accuracy: 0.9152 - val_loss: 0.3048 - val_accuracy: 0.8903\n","Epoch 33/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2226 - accuracy: 0.9182 - val_loss: 0.3003 - val_accuracy: 0.8942\n","Epoch 34/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2173 - accuracy: 0.9208 - val_loss: 0.3027 - val_accuracy: 0.8917\n","Epoch 35/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2158 - accuracy: 0.9201 - val_loss: 0.3070 - val_accuracy: 0.8929\n","Epoch 36/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.2132 - accuracy: 0.9220 - val_loss: 0.3017 - val_accuracy: 0.8926\n","Epoch 37/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2113 - accuracy: 0.9222 - val_loss: 0.3018 - val_accuracy: 0.8949\n","Epoch 38/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2081 - accuracy: 0.9223 - val_loss: 0.3097 - val_accuracy: 0.8909\n","Epoch 39/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2030 - accuracy: 0.9260 - val_loss: 0.3037 - val_accuracy: 0.8931\n","Epoch 40/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.2000 - accuracy: 0.9261 - val_loss: 0.3032 - val_accuracy: 0.8920\n","Epoch 41/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1979 - accuracy: 0.9269 - val_loss: 0.3107 - val_accuracy: 0.8912\n","Epoch 42/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1937 - accuracy: 0.9281 - val_loss: 0.3124 - val_accuracy: 0.8905\n","Epoch 43/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.1952 - accuracy: 0.9280 - val_loss: 0.3105 - val_accuracy: 0.8915\n","Epoch 44/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1901 - accuracy: 0.9302 - val_loss: 0.3066 - val_accuracy: 0.8935\n","Epoch 45/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1884 - accuracy: 0.9300 - val_loss: 0.3138 - val_accuracy: 0.8898\n","Epoch 46/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1837 - accuracy: 0.9322 - val_loss: 0.3106 - val_accuracy: 0.8928\n","Epoch 47/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1799 - accuracy: 0.9331 - val_loss: 0.3085 - val_accuracy: 0.8916\n","Epoch 48/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1819 - accuracy: 0.9324 - val_loss: 0.3125 - val_accuracy: 0.8934\n","Epoch 49/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1750 - accuracy: 0.9351 - val_loss: 0.3055 - val_accuracy: 0.8948\n","Epoch 50/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1772 - accuracy: 0.9344 - val_loss: 0.3130 - val_accuracy: 0.8923\n","Epoch 51/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1742 - accuracy: 0.9353 - val_loss: 0.3123 - val_accuracy: 0.8941\n","Epoch 52/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1725 - accuracy: 0.9362 - val_loss: 0.3099 - val_accuracy: 0.8947\n","Epoch 53/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1685 - accuracy: 0.9375 - val_loss: 0.3214 - val_accuracy: 0.8878\n","Epoch 54/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1636 - accuracy: 0.9399 - val_loss: 0.3090 - val_accuracy: 0.8936\n","Epoch 55/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1645 - accuracy: 0.9393 - val_loss: 0.3180 - val_accuracy: 0.8913\n","Epoch 56/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1601 - accuracy: 0.9405 - val_loss: 0.3137 - val_accuracy: 0.8955\n","Epoch 57/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1607 - accuracy: 0.9409 - val_loss: 0.3155 - val_accuracy: 0.8913\n","Epoch 58/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.1581 - accuracy: 0.9422 - val_loss: 0.3123 - val_accuracy: 0.8953\n","Epoch 59/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1542 - accuracy: 0.9432 - val_loss: 0.3133 - val_accuracy: 0.8939\n","Epoch 60/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.1531 - accuracy: 0.9438 - val_loss: 0.3239 - val_accuracy: 0.8924\n"]}]},{"cell_type":"code","source":["history02B = model02B.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDLR62dUIe6S","executionInfo":{"status":"ok","timestamp":1653481762380,"user_tz":-540,"elapsed":501917,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"3d60808d-ff44-43e2-900e-bbd211480a5b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1517 - accuracy: 0.9431 - val_loss: 0.3226 - val_accuracy: 0.8920\n","Epoch 2/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1499 - accuracy: 0.9439 - val_loss: 0.3202 - val_accuracy: 0.8928\n","Epoch 3/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1503 - accuracy: 0.9447 - val_loss: 0.3353 - val_accuracy: 0.8916\n","Epoch 4/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1477 - accuracy: 0.9454 - val_loss: 0.3238 - val_accuracy: 0.8939\n","Epoch 5/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1454 - accuracy: 0.9461 - val_loss: 0.3257 - val_accuracy: 0.8935\n","Epoch 6/60\n","375/375 [==============================] - 9s 24ms/step - loss: 0.1455 - accuracy: 0.9458 - val_loss: 0.3275 - val_accuracy: 0.8931\n","Epoch 7/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1422 - accuracy: 0.9469 - val_loss: 0.3257 - val_accuracy: 0.8948\n","Epoch 8/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1413 - accuracy: 0.9478 - val_loss: 0.3280 - val_accuracy: 0.8924\n","Epoch 9/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1412 - accuracy: 0.9477 - val_loss: 0.3310 - val_accuracy: 0.8938\n","Epoch 10/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1353 - accuracy: 0.9496 - val_loss: 0.3283 - val_accuracy: 0.8911\n","Epoch 11/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1348 - accuracy: 0.9506 - val_loss: 0.3319 - val_accuracy: 0.8948\n","Epoch 12/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1322 - accuracy: 0.9508 - val_loss: 0.3298 - val_accuracy: 0.8942\n","Epoch 13/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1315 - accuracy: 0.9509 - val_loss: 0.3375 - val_accuracy: 0.8911\n","Epoch 14/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1329 - accuracy: 0.9503 - val_loss: 0.3242 - val_accuracy: 0.8944\n","Epoch 15/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1278 - accuracy: 0.9518 - val_loss: 0.3282 - val_accuracy: 0.8974\n","Epoch 16/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1294 - accuracy: 0.9512 - val_loss: 0.3424 - val_accuracy: 0.8888\n","Epoch 17/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1276 - accuracy: 0.9519 - val_loss: 0.3404 - val_accuracy: 0.8932\n","Epoch 18/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1227 - accuracy: 0.9538 - val_loss: 0.3398 - val_accuracy: 0.8923\n","Epoch 19/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1247 - accuracy: 0.9538 - val_loss: 0.3408 - val_accuracy: 0.8970\n","Epoch 20/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1213 - accuracy: 0.9549 - val_loss: 0.3438 - val_accuracy: 0.8922\n","Epoch 21/60\n","375/375 [==============================] - 9s 24ms/step - loss: 0.1171 - accuracy: 0.9576 - val_loss: 0.3460 - val_accuracy: 0.8929\n","Epoch 22/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.1172 - accuracy: 0.9570 - val_loss: 0.3763 - val_accuracy: 0.8867\n","Epoch 23/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1177 - accuracy: 0.9567 - val_loss: 0.3456 - val_accuracy: 0.8957\n","Epoch 24/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1165 - accuracy: 0.9564 - val_loss: 0.3353 - val_accuracy: 0.8959\n","Epoch 25/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1187 - accuracy: 0.9564 - val_loss: 0.3429 - val_accuracy: 0.8964\n","Epoch 26/60\n","375/375 [==============================] - 9s 24ms/step - loss: 0.1136 - accuracy: 0.9588 - val_loss: 0.3539 - val_accuracy: 0.8935\n","Epoch 27/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1123 - accuracy: 0.9584 - val_loss: 0.3529 - val_accuracy: 0.8933\n","Epoch 28/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1088 - accuracy: 0.9592 - val_loss: 0.3536 - val_accuracy: 0.8923\n","Epoch 29/60\n","375/375 [==============================] - 10s 27ms/step - loss: 0.1079 - accuracy: 0.9591 - val_loss: 0.3608 - val_accuracy: 0.8910\n","Epoch 30/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1098 - accuracy: 0.9594 - val_loss: 0.3475 - val_accuracy: 0.8941\n","Epoch 31/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.1054 - accuracy: 0.9607 - val_loss: 0.3533 - val_accuracy: 0.8953\n","Epoch 32/60\n","375/375 [==============================] - 9s 23ms/step - loss: 0.1039 - accuracy: 0.9621 - val_loss: 0.3420 - val_accuracy: 0.8964\n","Epoch 33/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1067 - accuracy: 0.9599 - val_loss: 0.3473 - val_accuracy: 0.8939\n","Epoch 34/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.1036 - accuracy: 0.9619 - val_loss: 0.3549 - val_accuracy: 0.8924\n","Epoch 35/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1049 - accuracy: 0.9606 - val_loss: 0.3568 - val_accuracy: 0.8953\n","Epoch 36/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.1029 - accuracy: 0.9618 - val_loss: 0.3519 - val_accuracy: 0.8927\n","Epoch 37/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.1020 - accuracy: 0.9610 - val_loss: 0.3662 - val_accuracy: 0.8938\n","Epoch 38/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.0998 - accuracy: 0.9632 - val_loss: 0.3710 - val_accuracy: 0.8914\n","Epoch 39/60\n","375/375 [==============================] - 9s 25ms/step - loss: 0.0999 - accuracy: 0.9631 - val_loss: 0.3565 - val_accuracy: 0.8968\n","Epoch 40/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0960 - accuracy: 0.9649 - val_loss: 0.3660 - val_accuracy: 0.8943\n","Epoch 41/60\n","375/375 [==============================] - 9s 24ms/step - loss: 0.0951 - accuracy: 0.9649 - val_loss: 0.3630 - val_accuracy: 0.8955\n","Epoch 42/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.0982 - accuracy: 0.9632 - val_loss: 0.3741 - val_accuracy: 0.8927\n","Epoch 43/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.0962 - accuracy: 0.9634 - val_loss: 0.3669 - val_accuracy: 0.8953\n","Epoch 44/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0938 - accuracy: 0.9645 - val_loss: 0.3619 - val_accuracy: 0.8938\n","Epoch 45/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0928 - accuracy: 0.9657 - val_loss: 0.3784 - val_accuracy: 0.8907\n","Epoch 46/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.0949 - accuracy: 0.9648 - val_loss: 0.3683 - val_accuracy: 0.8938\n","Epoch 47/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0919 - accuracy: 0.9658 - val_loss: 0.3652 - val_accuracy: 0.8943\n","Epoch 48/60\n","375/375 [==============================] - 8s 20ms/step - loss: 0.0914 - accuracy: 0.9662 - val_loss: 0.3833 - val_accuracy: 0.8923\n","Epoch 49/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.0921 - accuracy: 0.9656 - val_loss: 0.3667 - val_accuracy: 0.8934\n","Epoch 50/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0934 - accuracy: 0.9650 - val_loss: 0.3775 - val_accuracy: 0.8923\n","Epoch 51/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0889 - accuracy: 0.9678 - val_loss: 0.3669 - val_accuracy: 0.8942\n","Epoch 52/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.0868 - accuracy: 0.9688 - val_loss: 0.3747 - val_accuracy: 0.8910\n","Epoch 53/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0873 - accuracy: 0.9673 - val_loss: 0.3924 - val_accuracy: 0.8945\n","Epoch 54/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0880 - accuracy: 0.9680 - val_loss: 0.3907 - val_accuracy: 0.8920\n","Epoch 55/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0836 - accuracy: 0.9690 - val_loss: 0.3798 - val_accuracy: 0.8932\n","Epoch 56/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0857 - accuracy: 0.9686 - val_loss: 0.3730 - val_accuracy: 0.8960\n","Epoch 57/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.0846 - accuracy: 0.9697 - val_loss: 0.3864 - val_accuracy: 0.8945\n","Epoch 58/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0803 - accuracy: 0.9698 - val_loss: 0.3773 - val_accuracy: 0.8945\n","Epoch 59/60\n","375/375 [==============================] - 9s 23ms/step - loss: 0.0816 - accuracy: 0.9703 - val_loss: 0.3805 - val_accuracy: 0.8917\n","Epoch 60/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.0810 - accuracy: 0.9701 - val_loss: 0.3862 - val_accuracy: 0.8933\n"]}]},{"cell_type":"code","source":["history08B = model08B.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpwYaT5yIg8A","executionInfo":{"status":"ok","timestamp":1653482265082,"user_tz":-540,"elapsed":502710,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"82620b31-e1d4-474d-b7ab-c453a655e539"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","375/375 [==============================] - 9s 22ms/step - loss: 2.0270 - accuracy: 0.3174 - val_loss: 1.0182 - val_accuracy: 0.6899\n","Epoch 2/60\n","375/375 [==============================] - 8s 21ms/step - loss: 1.3127 - accuracy: 0.5215 - val_loss: 0.7925 - val_accuracy: 0.7174\n","Epoch 3/60\n","375/375 [==============================] - 8s 22ms/step - loss: 1.0917 - accuracy: 0.5978 - val_loss: 0.7202 - val_accuracy: 0.7310\n","Epoch 4/60\n","375/375 [==============================] - 8s 23ms/step - loss: 0.9780 - accuracy: 0.6419 - val_loss: 0.6826 - val_accuracy: 0.7467\n","Epoch 5/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.9084 - accuracy: 0.6648 - val_loss: 0.6513 - val_accuracy: 0.7592\n","Epoch 6/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.8664 - accuracy: 0.6795 - val_loss: 0.6270 - val_accuracy: 0.7735\n","Epoch 7/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.8330 - accuracy: 0.6938 - val_loss: 0.6119 - val_accuracy: 0.7798\n","Epoch 8/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.7945 - accuracy: 0.7103 - val_loss: 0.5912 - val_accuracy: 0.7910\n","Epoch 9/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.7730 - accuracy: 0.7209 - val_loss: 0.5788 - val_accuracy: 0.7929\n","Epoch 10/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.7496 - accuracy: 0.7301 - val_loss: 0.5668 - val_accuracy: 0.7987\n","Epoch 11/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.7304 - accuracy: 0.7375 - val_loss: 0.5528 - val_accuracy: 0.8023\n","Epoch 12/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.7153 - accuracy: 0.7436 - val_loss: 0.5410 - val_accuracy: 0.8085\n","Epoch 13/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.7087 - accuracy: 0.7469 - val_loss: 0.5315 - val_accuracy: 0.8152\n","Epoch 14/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6916 - accuracy: 0.7518 - val_loss: 0.5282 - val_accuracy: 0.8126\n","Epoch 15/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6780 - accuracy: 0.7562 - val_loss: 0.5207 - val_accuracy: 0.8164\n","Epoch 16/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.6705 - accuracy: 0.7635 - val_loss: 0.5104 - val_accuracy: 0.8201\n","Epoch 17/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.6637 - accuracy: 0.7643 - val_loss: 0.5092 - val_accuracy: 0.8200\n","Epoch 18/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6525 - accuracy: 0.7688 - val_loss: 0.5065 - val_accuracy: 0.8197\n","Epoch 19/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6432 - accuracy: 0.7729 - val_loss: 0.4975 - val_accuracy: 0.8245\n","Epoch 20/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6346 - accuracy: 0.7757 - val_loss: 0.4946 - val_accuracy: 0.8248\n","Epoch 21/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.6302 - accuracy: 0.7789 - val_loss: 0.4845 - val_accuracy: 0.8290\n","Epoch 22/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6200 - accuracy: 0.7822 - val_loss: 0.4837 - val_accuracy: 0.8287\n","Epoch 23/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.6201 - accuracy: 0.7817 - val_loss: 0.4764 - val_accuracy: 0.8322\n","Epoch 24/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6093 - accuracy: 0.7862 - val_loss: 0.4742 - val_accuracy: 0.8320\n","Epoch 25/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6088 - accuracy: 0.7852 - val_loss: 0.4706 - val_accuracy: 0.8326\n","Epoch 26/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.6001 - accuracy: 0.7893 - val_loss: 0.4635 - val_accuracy: 0.8363\n","Epoch 27/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5914 - accuracy: 0.7919 - val_loss: 0.4606 - val_accuracy: 0.8363\n","Epoch 28/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5911 - accuracy: 0.7927 - val_loss: 0.4634 - val_accuracy: 0.8377\n","Epoch 29/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5868 - accuracy: 0.7931 - val_loss: 0.4552 - val_accuracy: 0.8378\n","Epoch 30/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5837 - accuracy: 0.7949 - val_loss: 0.4559 - val_accuracy: 0.8380\n","Epoch 31/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5785 - accuracy: 0.7972 - val_loss: 0.4505 - val_accuracy: 0.8412\n","Epoch 32/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.5754 - accuracy: 0.7964 - val_loss: 0.4495 - val_accuracy: 0.8424\n","Epoch 33/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5723 - accuracy: 0.7999 - val_loss: 0.4442 - val_accuracy: 0.8440\n","Epoch 34/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5660 - accuracy: 0.8030 - val_loss: 0.4430 - val_accuracy: 0.8440\n","Epoch 35/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5597 - accuracy: 0.8034 - val_loss: 0.4424 - val_accuracy: 0.8438\n","Epoch 36/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5587 - accuracy: 0.8029 - val_loss: 0.4399 - val_accuracy: 0.8444\n","Epoch 37/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5553 - accuracy: 0.8061 - val_loss: 0.4357 - val_accuracy: 0.8453\n","Epoch 38/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5571 - accuracy: 0.8037 - val_loss: 0.4326 - val_accuracy: 0.8472\n","Epoch 39/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5475 - accuracy: 0.8095 - val_loss: 0.4324 - val_accuracy: 0.8473\n","Epoch 40/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5465 - accuracy: 0.8098 - val_loss: 0.4343 - val_accuracy: 0.8458\n","Epoch 41/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.5457 - accuracy: 0.8105 - val_loss: 0.4293 - val_accuracy: 0.8489\n","Epoch 42/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5445 - accuracy: 0.8107 - val_loss: 0.4251 - val_accuracy: 0.8506\n","Epoch 43/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5407 - accuracy: 0.8119 - val_loss: 0.4275 - val_accuracy: 0.8493\n","Epoch 44/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5365 - accuracy: 0.8124 - val_loss: 0.4280 - val_accuracy: 0.8492\n","Epoch 45/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.5337 - accuracy: 0.8131 - val_loss: 0.4274 - val_accuracy: 0.8475\n","Epoch 46/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.5322 - accuracy: 0.8151 - val_loss: 0.4213 - val_accuracy: 0.8504\n","Epoch 47/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5297 - accuracy: 0.8162 - val_loss: 0.4190 - val_accuracy: 0.8511\n","Epoch 48/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5303 - accuracy: 0.8165 - val_loss: 0.4223 - val_accuracy: 0.8485\n","Epoch 49/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5214 - accuracy: 0.8184 - val_loss: 0.4187 - val_accuracy: 0.8528\n","Epoch 50/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5187 - accuracy: 0.8184 - val_loss: 0.4187 - val_accuracy: 0.8513\n","Epoch 51/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5221 - accuracy: 0.8167 - val_loss: 0.4161 - val_accuracy: 0.8518\n","Epoch 52/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5159 - accuracy: 0.8184 - val_loss: 0.4137 - val_accuracy: 0.8529\n","Epoch 53/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5158 - accuracy: 0.8195 - val_loss: 0.4147 - val_accuracy: 0.8528\n","Epoch 54/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5105 - accuracy: 0.8220 - val_loss: 0.4125 - val_accuracy: 0.8531\n","Epoch 55/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5077 - accuracy: 0.8229 - val_loss: 0.4102 - val_accuracy: 0.8545\n","Epoch 56/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5089 - accuracy: 0.8235 - val_loss: 0.4075 - val_accuracy: 0.8551\n","Epoch 57/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.5059 - accuracy: 0.8228 - val_loss: 0.4047 - val_accuracy: 0.8559\n","Epoch 58/60\n","375/375 [==============================] - 8s 22ms/step - loss: 0.5015 - accuracy: 0.8241 - val_loss: 0.4059 - val_accuracy: 0.8569\n","Epoch 59/60\n","375/375 [==============================] - 9s 23ms/step - loss: 0.5077 - accuracy: 0.8228 - val_loss: 0.4050 - val_accuracy: 0.8563\n","Epoch 60/60\n","375/375 [==============================] - 8s 21ms/step - loss: 0.5025 - accuracy: 0.8238 - val_loss: 0.4081 - val_accuracy: 0.8565\n"]}]},{"cell_type":"code","source":["metrics02B = model02B.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics02B[1])\n","print(f'Accuracy: {metrics02B[1]*100:.2f}%\\n')\n","\n","metrics05B = model05.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics05[1])\n","print(f'Accuracy: {metrics05[1]*100:.2f}%\\n')\n","\n","metrics08 = model08.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics08[1])\n","print(f'Accuracy: {metrics08[1]*100:.2f}%\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38IZo_3nIhhD","executionInfo":{"status":"ok","timestamp":1653482293111,"user_tz":-540,"elapsed":4063,"user":{"displayName":"조이준","userId":"18430695341039920489"}},"outputId":"82254fb6-db12-4311-800b-0d6b04a1da3e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 4ms/step - loss: 0.4171 - accuracy: 0.8910\n","0.890999972820282\n","Accuracy: 89.10%\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8708\n","0.8708000183105469\n","Accuracy: 87.08%\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 0.4189 - accuracy: 0.8514\n","0.8514000177383423\n","Accuracy: 85.14%\n","\n"]}]},{"cell_type":"markdown","source":["# 과제 결과 확인용"],"metadata":{"id":"Bpd-ekcVLaaN"}},{"cell_type":"markdown","source":["### Dropout 만 사용하는 경우\n","### p = 0.2"],"metadata":{"id":"Cv3hvhNPLFBL"}},{"cell_type":"code","source":["metrics02 = model02.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics02[1])\n","print(f'Accuracy: {metrics02[1]*100:.2f}%\\n')"],"metadata":{"id":"5bXdsyJYLD1e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dropout만 사용하는 경우\n","### p = 0.5"],"metadata":{"id":"qzmH6sLXLNQ0"}},{"cell_type":"code","source":["metrics05 = model05.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics05[1])\n","print(f'Accuracy: {metrics05[1]*100:.2f}%\\n')"],"metadata":{"id":"1GLiJ9ijLM9z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dropout만 사용하는 경우\n","### p = 0.8"],"metadata":{"id":"CmBz2Sb1LTgF"}},{"cell_type":"code","source":["metrics08 = model08.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics08[1])\n","print(f'Accuracy: {metrics08[1]*100:.2f}%\\n')"],"metadata":{"id":"ujZqbI0eLXCM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### BN을 추가하는 경우\n","### p = 0.2"],"metadata":{"id":"aArKCL-gLgx5"}},{"cell_type":"code","source":["metrics02B = model02B.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics02B[1])\n","print(f'Accuracy: {metrics02B[1]*100:.2f}%\\n')"],"metadata":{"id":"sk3ZPgYSLY4Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### BN을 추가하는 경우\n","### p = 0.5"],"metadata":{"id":"AiZyn_pxLnJe"}},{"cell_type":"code","source":["metrics05B = model05.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics05[1])\n","print(f'Accuracy: {metrics05[1]*100:.2f}%\\n')"],"metadata":{"id":"8b2ZE99WLpoW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### BN을 추가하는 경우\n","### p = 0.8"],"metadata":{"id":"cg07G_WlLqv-"}},{"cell_type":"code","source":["metrics08 = model08.evaluate(x_test, y_test) #returns loss and accuracy\n","print(metrics08[1])\n","print(f'Accuracy: {metrics08[1]*100:.2f}%\\n')"],"metadata":{"id":"FGBmRWo2LsrM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 정확도가 변화하는 양상을 관찰한 결과와 이유\n","\n","#### 1. Dropout을 사용하는 이유\n","\n","dropout을 이용하는 이유는 overfitting 문제를 해소하기 위함인 데, 학습의 과정에서 은닉층의 유닛을 p의 확률로 제거하는 것이다. 하지만 이것은 학습에만 적용을 하고 테스트 시에는 확실한 결과를 위해 dropout을 적용하지 않는다.(p=1)\n","\n","#### 2. Batch Normalization을 하는 이유\n","\n","학습을 배치 단위로 나누어 수행하는 데 각 배치를 정규화하는 것이다. 배치의 평균과 분산을 신경망 안에서 조정하여 학습과 함께 진행하는 것이다.\n","Scale과 Shift를 통해 변환하여 비선형성을 유지한다.\n","\n","#### 3. 변화 양상과 양상을 보이는 이유\n","\n","결과를 살펴보면 p=0.5, 0.8일 때는 정확도가 동일한 값으로 나왔고 p=0.2일 때, BN을 사용한 경우가 조금 더 높았지만 작은 차이를 보여 변화가 거의 없다고 얘기할 수 있다.\n","이는 둘 다 regulization을 수행하기 때문에 동일한 효과를 적용한 것이므로 차이를 만들지 못했다고 볼 수 있다."],"metadata":{"id":"ws6x91kML06i"}},{"cell_type":"code","source":[""],"metadata":{"id":"DkpY1I8qL6dD"},"execution_count":null,"outputs":[]}]}